import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc
import matplotlib.pyplot as plt
import torch.nn.functional as F

# ğŸ”§ GPU 3ê°œ ì„¤ì • ì¶”ê°€
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2"  # GPU 0, 1, 2 ì‚¬ìš©
torch.cuda.manual_seed_all(42)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print('Device:', device)
print('Current cuda device:', torch.cuda.current_device())
print('Count of using GPUs:', torch.cuda.device_count())

# ğŸ”§ í•„ìš”í•œ ë³´ì¡° í´ë˜ìŠ¤ë“¤ êµ¬í˜„

class PeakAwareAugmentation:
    def __init__(self, noise_std=0.02, amplitude_range=(0.9, 1.1)):
        self.noise_std = noise_std
        self.amplitude_range = amplitude_range
    
    def add_realistic_noise(self, data, peak_indices):
        """ì‹¤ì œ ì„¼ì„œ ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜"""
        noise = np.random.normal(0, self.noise_std, data.shape)
        return data + noise
    
    def amplitude_scaling(self, data, scale_factor=None):
        """ì§„í­ ìŠ¤ì¼€ì¼ë§"""
        if scale_factor is None:
            scale_factor = np.random.uniform(*self.amplitude_range)
        baseline = np.percentile(data, 10)
        scaled_data = baseline + (data - baseline) * scale_factor
        return scaled_data

class SmartBatchSampler:
    """Peak ì¤‘ì‹¬ì˜ ì§€ëŠ¥ì  ë°°ì¹˜ ìƒ˜í”Œë§"""
    
    def __init__(self, dataset, batch_size, peak_ratio=0.3):
        self.dataset = dataset
        self.batch_size = batch_size
        self.peak_ratio = peak_ratio
        
        # Peak/Non-peak ìƒ˜í”Œ êµ¬ë¶„
        self.peak_indices = []
        self.normal_indices = []
        
        for i, (_, label) in enumerate(dataset):
            if torch.max(label) > 0.7:  # Peak ìƒ˜í”Œ
                self.peak_indices.append(i)
            else:  # Normal ìƒ˜í”Œ
                self.normal_indices.append(i)
        
        print(f"ğŸ“Š Smart Sampler: {len(self.peak_indices)} peak samples, {len(self.normal_indices)} normal samples")
    
    def __iter__(self):
        # ë°°ì¹˜ë³„ë¡œ Peak/Normal ë¹„ìœ¨ ì¡°ì •
        peak_per_batch = int(self.batch_size * self.peak_ratio)
        normal_per_batch = self.batch_size - peak_per_batch
        
        # ì¸ë±ìŠ¤ ì…”í”Œ
        np.random.shuffle(self.peak_indices)
        np.random.shuffle(self.normal_indices)
        
        peak_idx = 0
        normal_idx = 0
        
        while peak_idx < len(self.peak_indices) or normal_idx < len(self.normal_indices):
            batch_indices = []
            
            # Peak ìƒ˜í”Œ ì¶”ê°€
            for _ in range(peak_per_batch):
                if peak_idx < len(self.peak_indices):
                    batch_indices.append(self.peak_indices[peak_idx])
                    peak_idx += 1
            
            # Normal ìƒ˜í”Œ ì¶”ê°€
            for _ in range(normal_per_batch):
                if normal_idx < len(self.normal_indices):
                    batch_indices.append(self.normal_indices[normal_idx])
                    normal_idx += 1
            
            if len(batch_indices) > 0:
                np.random.shuffle(batch_indices)  # ë°°ì¹˜ ë‚´ ì…”í”Œ
                yield batch_indices
    
    def __len__(self):
        total_samples = len(self.peak_indices) + len(self.normal_indices)
        return (total_samples + self.batch_size - 1) // self.batch_size

# ğŸ”§ Hybrid Loss êµ¬í˜„
class HybridPeakDetectionLoss(nn.Module):
    def __init__(self, 
                 focal_alpha=0.99, 
                 focal_gamma=2.0,
                 dice_weight=0.3,
                 peak_force_weight=2.0):
        super().__init__()
        self.focal_alpha = focal_alpha
        self.focal_gamma = focal_gamma
        self.dice_weight = dice_weight
        self.peak_force_weight = peak_force_weight
        
    def focal_loss(self, pred_logits, target):
        """Focal Loss: ë¶ˆê· í˜• ë°ì´í„° í•´ê²°"""
        pred_probs = torch.sigmoid(pred_logits)
        ce_loss = F.binary_cross_entropy_with_logits(pred_logits, target, reduction='none')
        
        # p_t ê³„ì‚°
        p_t = pred_probs * target + (1 - pred_probs) * (1 - target)
        
        # Alpha weighting
        alpha_t = self.focal_alpha * target + (1 - self.focal_alpha) * (1 - target)
        
        # Focal term
        focal_term = (1 - p_t) ** self.focal_gamma
        
        focal_loss = alpha_t * focal_term * ce_loss
        return focal_loss.mean()
    
    def dice_loss(self, pred_logits, target):
        """Dice Loss: ì—°ì†ì„±ê³¼ í˜•íƒœ ë³´ì¡´"""
        pred_probs = torch.sigmoid(pred_logits)
        
        # Smooth parameter to avoid division by zero
        smooth = 1e-6
        
        # Flatten
        pred_flat = pred_probs.view(-1)
        target_flat = target.view(-1)
        
        # Dice coefficient
        intersection = (pred_flat * target_flat).sum()
        dice_coeff = (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)
        
        return 1 - dice_coeff
    
    def peak_forcing_loss(self, pred_logits, target):
        """Peak Forcing: 1.0 ë‹¬ì„±ì„ ìœ„í•œ ê°•ì œ í•™ìŠµ"""
        pred_probs = torch.sigmoid(pred_logits)
        
        # Peak ì˜ì—­ ì‹ë³„ (0.9 ì´ìƒ)
        peak_mask = target > 0.9
        
        if peak_mask.any():
            # Peak ì˜ì—­ì—ì„œ 0.95 ì´ìƒ ê°•ì œ í•™ìŠµ
            peak_preds = pred_probs[peak_mask]
            peak_targets = torch.ones_like(peak_preds) * 0.98  # 0.98 ëª©í‘œ
            
            # MSEë¡œ ì§ì ‘ì  ê°’ ê°•ì œ
            peak_loss = F.mse_loss(peak_preds, peak_targets)
            return peak_loss
        else:
            return torch.tensor(0.0, device=pred_logits.device)
    
    def forward(self, pred_logits, target):
        # 1. Focal Loss: ë¶ˆê· í˜• í•´ê²°
        focal = self.focal_loss(pred_logits, target)
        
        # 2. Dice Loss: í˜•íƒœ ë³´ì¡´
        dice = self.dice_loss(pred_logits, target)
        
        # 3. Peak Forcing: 1.0 ë‹¬ì„±
        peak_force = self.peak_forcing_loss(pred_logits, target)
        
        # ì´ ì†ì‹¤
        total_loss = (focal + 
                     self.dice_weight * dice + 
                     self.peak_force_weight * peak_force)
        
        return total_loss, {
            'focal': focal.item(),
            'dice': dice.item(),
            'peak_force': peak_force.item()
        }

# ğŸ”§ Multi-Head ëª¨ë¸ êµ¬í˜„
class MultiHeadPeakDetector(nn.Module):
    def __init__(self, input_size=1, hidden_size=512, num_layers=2):
        super().__init__()
        
        # ê³µí†µ feature extractor
        self.feature_extractor = nn.LSTM(
            input_size, hidden_size, num_layers,
            batch_first=True, dropout=0.1, bidirectional=False
        )
        
        # Head 1: Background/Normal ê²€ì¶œ
        self.background_head = nn.Sequential(
            nn.Linear(hidden_size, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
        # Head 2: Peak ê²€ì¶œ (í•µì‹¬ êµ¬ê°„)
        self.peak_head = nn.Sequential(
            nn.Linear(hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(0.05),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
        
        # Final fusion layer
        self.fusion = nn.Sequential(
            nn.Linear(2, 8),  # 2ê°œ head ì¶œë ¥
            nn.ReLU(),
            nn.Linear(8, 1)
        )
        
    def forward(self, x, return_heads=False):
        # Feature extraction
        lstm_out, _ = self.feature_extractor(x)
        features = lstm_out[:, -1, :]
        
        # ê° headë³„ ì˜ˆì¸¡
        background_prob = self.background_head(features)
        peak_logit = self.peak_head(features)
        peak_prob = torch.sigmoid(peak_logit * 1.2)  # ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ 1.0 ê·¼ì ‘
        
        if return_heads:
            return {
                'background': background_prob.squeeze(),
                'peak': peak_prob.squeeze(),
                'peak_logit': peak_logit.squeeze()
            }
        
        # ìµœì¢… ìœµí•©
        head_outputs = torch.cat([
            background_prob,
            peak_prob
        ], dim=1)
        
        final_output = self.fusion(head_outputs)
        return final_output.squeeze()

# ğŸ”§ Multi-Stage Trainer êµ¬í˜„
class MultiStageTrainer:
    def __init__(self, model, device):
        self.model = model
        self.device = device
        
        # ë‹¨ê³„ë³„ í•™ìŠµì„ ìœ„í•œ ë‹¤ì¤‘ optimizer
        self.background_optimizer = torch.optim.Adam(
            list(model.module.feature_extractor.parameters()) + 
            list(model.module.background_head.parameters()) if hasattr(model, 'module') 
            else list(model.feature_extractor.parameters()) + 
            list(model.background_head.parameters()),
            lr=0.001
        )
        
        self.peak_optimizer = torch.optim.Adam(
            list(model.module.feature_extractor.parameters()) + 
            list(model.module.peak_head.parameters()) if hasattr(model, 'module')
            else list(model.feature_extractor.parameters()) + 
            list(model.peak_head.parameters()),
            lr=0.0001
        )
        
        self.fusion_optimizer = torch.optim.Adam(
            model.module.fusion.parameters() if hasattr(model, 'module') 
            else model.fusion.parameters(),
            lr=0.0005
        )
        
        # ë‹¨ê³„ë³„ loss
        self.background_loss = nn.BCELoss()
        self.peak_loss = HybridPeakDetectionLoss()
        self.fusion_loss = nn.MSELoss()
        
    def train_stage1_background(self, dataloader, epochs=15):
        """Stage 1: Background/Normal êµ¬ê°„ í•™ìŠµ"""
        print("ğŸ”¹ Stage 1: Background Detection Training")
        
        self.model.train()
        for epoch in range(epochs):
            total_loss = 0
            batch_count = 0
            for batch_idx, (x, y) in enumerate(dataloader):
                x, y = x.to(self.device).unsqueeze(-1), y.to(self.device)
                
                self.background_optimizer.zero_grad()
                
                # Background ë¼ë²¨ ìƒì„± (0.3 ì´í•˜ëŠ” background)
                background_labels = (y <= 0.3).float()
                
                heads = self.model(x, return_heads=True)
                background_pred = heads['background']
                
                loss = self.background_loss(background_pred, background_labels)
                loss.backward()
                self.background_optimizer.step()
                
                total_loss += loss.item()
                batch_count += 1
                
                if batch_idx % 100 == 0:
                    print(f"Epoch {epoch+1}/{epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}")
                    
                    # ì¤‘ê°„ ì„±ëŠ¥ ì²´í¬ (Stage 1)
                    if epoch > 0 and batch_idx % 500 == 0:
                        self.model.eval()
                        with torch.no_grad():
                            sample_x, sample_y = next(iter(dataloader))
                            sample_x = sample_x[:8].to(self.device).unsqueeze(-1)
                            sample_y = sample_y[:8].to(self.device)
                            
                            heads = self.model(sample_x, return_heads=True)
                            bg_acc = ((heads['background'] > 0.5) == (sample_y <= 0.3)).float().mean()
                            print(f"   Background Accuracy: {bg_acc:.3f}")
                        self.model.train()
        
        print(f"Stage 1 Complete. Avg Loss: {total_loss/batch_count:.4f}")
    
    def train_stage2_peak(self, dataloader, epochs=25):
        """Stage 2: Peak êµ¬ê°„ íŠ¹í™” í•™ìŠµ"""
        print("ğŸ”¹ Stage 2: Peak Detection Training")
        
        self.model.train()
        for epoch in range(epochs):
            total_loss = 0
            batch_count = 0
            for batch_idx, (x, y) in enumerate(dataloader):
                x, y = x.to(self.device).unsqueeze(-1), y.to(self.device)
                
                self.peak_optimizer.zero_grad()
                
                heads = self.model(x, return_heads=True)
                peak_logit = heads['peak_logit']
                
                # Peak ì˜ì—­ë§Œ í•™ìŠµ (0.7 ì´ìƒ)
                peak_mask = y >= 0.7
                if peak_mask.any():
                    peak_targets = y[peak_mask]
                    peak_preds = peak_logit[peak_mask]
                    
                    loss, loss_components = self.peak_loss(peak_preds, peak_targets)
                    loss.backward()
                    self.peak_optimizer.step()
                    
                    total_loss += loss.item()
                    batch_count += 1
                    
                    if batch_idx % 100 == 0:
                        print(f"Epoch {epoch+1}/{epochs}, Batch {batch_idx}")
                        print(f"Loss: {loss.item():.4f}, Components: {loss_components}")
                        
                        # Peak ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (Stage 2)
                        if epoch > 2 and batch_idx % 300 == 0:
                            with torch.no_grad():
                                peak_probs = torch.sigmoid(peak_preds)
                                max_peak = peak_probs.max().item()
                                mean_peak = peak_probs.mean().item()
                                above_09 = (peak_probs > 0.9).sum().item()
                                above_095 = (peak_probs > 0.95).sum().item()
                                
                                print(f"   Peak Stats - Max: {max_peak:.3f}, Mean: {mean_peak:.3f}")
                                print(f"   Above 0.9: {above_09}, Above 0.95: {above_095}")
        
        print(f"Stage 2 Complete. Avg Loss: {total_loss/max(1, batch_count):.4f}")
    
    def train_stage3_fusion(self, dataloader, epochs=30):
        """Stage 3: ì „ì²´ ìœµí•© í•™ìŠµ"""
        print("ğŸ”¹ Stage 3: Full Integration Training")
        
        self.model.train()
        for epoch in range(epochs):
            total_loss = 0
            batch_count = 0
            for batch_idx, (x, y) in enumerate(dataloader):
                x, y = x.to(self.device).unsqueeze(-1), y.to(self.device)
                
                self.fusion_optimizer.zero_grad()
                
                final_pred = self.model(x)
                loss = self.fusion_loss(final_pred, y)
                
                loss.backward()
                self.fusion_optimizer.step()
                
                total_loss += loss.item()
                batch_count += 1
                
                if batch_idx % 100 == 0:
                    print(f"Epoch {epoch+1}/{epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}")
                    
                    # ì „ì²´ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (Stage 3)
                    if epoch > 5 and batch_idx % 200 == 0:
                        self.model.eval()
                        with torch.no_grad():
                            sample_x, sample_y = next(iter(dataloader))
                            sample_x = sample_x[:8].to(self.device).unsqueeze(-1)
                            sample_y = sample_y[:8].to(self.device)
                            
                            final_pred = self.model(sample_x)
                            max_pred = final_pred.max().item()
                            mse = F.mse_loss(final_pred, sample_y).item()
                            
                            print(f"   Integration Stats - Max Pred: {max_pred:.3f}, MSE: {mse:.4f}")
                        self.model.train()
        
        print(f"Stage 3 Complete. Avg Loss: {total_loss/batch_count:.4f}")

# ğŸ”§ ë°ì´í„°ì…‹ êµ¬í˜„ (ê¸°ì¡´ê³¼ ë™ì¼)
class EnhancedPeakDataset(Dataset):
    def __init__(self, file_dir, seq_len, range_list, needle_dis, is_training=True):
        self.file_dir = file_dir
        self.seq_len = seq_len
        self.range_list = range_list
        self.needle_dis = needle_dis
        self.is_training = is_training
        
        # ì¦ê°• í´ë˜ìŠ¤ ì´ˆê¸°í™”
        self.augmentor = PeakAwareAugmentation() if is_training else None
        
        self.x_seq = []
        self.y_seq = []
        
        self._load_data()
        
    def _create_multi_stage_labels(self, data_length, indices):
        """ë‹¤ë‹¨ê³„ confidence ë¼ë²¨ ìƒì„±"""
        label_array = np.zeros(data_length, dtype=np.float32)
        
        if len(indices) >= 2:
            peak_center = indices[1]
            
            # 5ë‹¨ê³„ ë¼ë²¨ë§
            label_array[peak_center-200:peak_center-100] = 0.2  # ì›ê±°ë¦¬ ì˜ˆê³ 
            label_array[peak_center-100:peak_center-50] = 0.4   # ì¤‘ê±°ë¦¬ ì‹ í˜¸
            label_array[peak_center-50:peak_center-20] = 0.7    # ê·¼ê±°ë¦¬ ìƒìŠ¹
            label_array[peak_center-20:peak_center+20] = 1.0    # Peak êµ¬ê°„
            label_array[peak_center+20:peak_center+50] = 0.7    # í•˜ê°• êµ¬ê°„
            label_array[peak_center+50:peak_center+100] = 0.4   # í›„ì²˜ë¦¬
            
        return label_array
    
    def _load_data(self):
        """ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"""
        for ind in self.needle_dis:
            for i in self.range_list:
                try:
                    file_path = os.path.join(self.file_dir, f'T2D_{ind}/SavedData_{i:03d}.bin')
                    with open(file_path, 'rb') as file1:
                        data = np.frombuffer(file1.read(), dtype=np.float32).reshape(-1, 5).T.copy()
                        nor_x = data[0] - data[0][0]
                        
                        if np.isnan(nor_x).any() or np.isinf(nor_x).any():
                            continue
                            
                        indices = np.where(data[4] == 1)[0]
                        if len(indices) < 2:
                            continue
                        
                        # ë‹¤ë‹¨ê³„ ë¼ë²¨ ìƒì„±
                        label_array = self._create_multi_stage_labels(len(nor_x), indices)
                        
                        if len(nor_x) == 0 or np.all(label_array == 0):
                            continue
                        
                        # ì‹œí€€ìŠ¤ ìƒì„±
                        for j in range(self.seq_len, len(nor_x) - self.seq_len):
                            x_win = nor_x[j - self.seq_len : j]
                            y_win = label_array[j]
                            
                            if np.isnan(x_win).any() or np.isinf(x_win).any():
                                continue
                            if np.isnan(y_win) or np.isinf(y_win):
                                continue
                            
                            self.x_seq.append(torch.tensor(x_win, dtype=torch.float32))
                            self.y_seq.append(torch.tensor(y_win, dtype=torch.float32))
                        
                        print(f'{ind}_{i} processed: {len(nor_x)} points')
                        
                except Exception as e:
                    print(f"Error processing {ind}_{i}: {e}")
                    continue
        
        print(f'Total sequences loaded: {len(self.x_seq)}')
        
        # í›ˆë ¨ ì‹œ ë°ì´í„° ì¦ê°•
        if self.is_training and self.augmentor and len(self.x_seq) > 0:
            self._apply_augmentation()
    
    def _apply_augmentation(self):
        """ë°ì´í„° ì¦ê°• ì ìš©"""
        print("Applying data augmentation...")
        
        original_count = len(self.x_seq)
        augmented_data = []
        augmented_labels = []
        
        # Peak ìƒ˜í”Œ ì‹ë³„ ë° ì¦ê°•
        peak_samples = []
        for i, y in enumerate(self.y_seq):
            if y.item() > 0.7:  # Peak ìƒ˜í”Œ
                peak_samples.append(i)
        
        print(f"Found {len(peak_samples)} peak samples out of {original_count}")
        
        # Peak ìƒ˜í”Œ 2ë°° ì¦ê°•
        for idx in peak_samples[:min(len(peak_samples), 1000)]:  # ìµœëŒ€ 1000ê°œë§Œ
            x_orig = self.x_seq[idx].numpy()
            y_orig = self.y_seq[idx].numpy()
            
            # 2ê°œì˜ ì¦ê°• ë²„ì „ ìƒì„±
            for _ in range(2):
                # ë…¸ì´ì¦ˆ ì¶”ê°€
                x_aug = self.augmentor.add_realistic_noise(x_orig.copy(), [len(x_orig)//2])
                
                # ì§„í­ ìŠ¤ì¼€ì¼ë§
                x_aug = self.augmentor.amplitude_scaling(x_aug)
                
                augmented_data.append(torch.tensor(x_aug, dtype=torch.float32))
                augmented_labels.append(torch.tensor(y_orig, dtype=torch.float32))
        
        # ì¦ê°•ëœ ë°ì´í„° ì¶”ê°€
        self.x_seq.extend(augmented_data)
        self.y_seq.extend(augmented_labels)
        
        print(f"Augmentation complete: {original_count} â†’ {len(self.x_seq)} samples")
    
    def __len__(self):
        return len(self.x_seq)
    
    def __getitem__(self, idx):
        return self.x_seq[idx], self.y_seq[idx]

# ğŸ”§ Comprehensive Trainer
class ComprehensiveTrainer:
    def __init__(self, model, device, save_dir="./models"):
        self.model = model
        self.device = device
        self.save_dir = save_dir
        
        os.makedirs(save_dir, exist_ok=True)
        
        # ë‹¤ë‹¨ê³„ í•™ìŠµì„ ìœ„í•œ ì»´í¬ë„ŒíŠ¸
        self.multi_stage_trainer = MultiStageTrainer(model, device)
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        self.train_losses = []
        self.val_losses = []
        self.val_aucs = []
        self.peak_achievements = []
        
    def evaluate_comprehensive(self, val_loader):
        """í¬ê´„ì  í‰ê°€"""
        self.model.eval()
        all_preds = []
        all_labels = []
        peak_preds = []
        
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(self.device).unsqueeze(-1), y.to(self.device)
                
                # ë©”ì¸ ì˜ˆì¸¡
                main_pred = torch.sigmoid(self.model(x))
                
                all_preds.extend(main_pred.cpu().numpy())
                all_labels.extend(y.cpu().numpy())
                
                # Peak ì˜ì—­ ë³„ë„ í‰ê°€
                peak_mask = y > 0.8
                if peak_mask.any():
                    peak_preds.extend(main_pred[peak_mask].cpu().numpy())
        
        # ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ê³„ì‚°
        results = {}
        
        # 1. ì „ì²´ AUC (ë‹¤ì–‘í•œ ì„ê³„ê°’)
        binary_labels_07 = [1 if l > 0.7 else 0 for l in all_labels]
        
        if len(set(binary_labels_07)) > 1:
            results['auc_0.7'] = roc_auc_score(binary_labels_07, all_preds)
        
        # 2. Peak ì„±ëŠ¥
        if peak_preds:
            results['peak_max'] = max(peak_preds)
            results['peak_mean'] = np.mean(peak_preds)
            results['peak_above_0.9'] = sum(1 for p in peak_preds if p > 0.9)
            results['peak_above_0.95'] = sum(1 for p in peak_preds if p > 0.95)
            results['peak_above_0.98'] = sum(1 for p in peak_preds if p > 0.98)
        
        return results
    
    def train_progressive(self, train_loader, val_loader):
        """ì ì§„ì  í•™ìŠµ ì‹¤í–‰"""
        print("ğŸš€ Starting Progressive Training")
        
        # Stage 1: Background mastery
        print("\n" + "="*60)
        self.multi_stage_trainer.train_stage1_background(train_loader, epochs=15)
        
        # Stage 2: Peak specialization  
        print("\n" + "="*60)
        self.multi_stage_trainer.train_stage2_peak(train_loader, epochs=25)
        
        # Stage 3: Integration
        print("\n" + "="*60)
        self.multi_stage_trainer.train_stage3_fusion(train_loader, epochs=30)
        
        # ìµœì¢… í‰ê°€
        final_results = self.evaluate_comprehensive(val_loader)
        print("\nğŸ¯ Final Results:")
        for key, value in final_results.items():
            print(f"   {key}: {value:.4f}")
        
        # ëª¨ë¸ ì €ì¥
        torch.save(self.model.state_dict(), 
                  os.path.join(self.save_dir, "progressive_peak_detector.pth"))
        
        return final_results

# ğŸ”§ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main_training_pipeline():
    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    file_dir = '/home/ibom002/dataset/Data_20250709'
    seq_len = 512
    # GPU 3ê°œ ì‚¬ìš©ì‹œ ë°°ì¹˜ í¬ê¸° ì¦ê°€
    batch_size = 384  # ë©”ëª¨ë¦¬ ì•ˆì „ì„ ìœ„í•´ ì¡°ì •
    
    print(f"ğŸ”§ Using device: {device}")
    print(f"ğŸ”§ Batch size optimized for {torch.cuda.device_count()} GPUs: {batch_size}")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    print("ğŸ“‚ Loading datasets...")
    train_ds = EnhancedPeakDataset(
        file_dir, seq_len, 
        range_list=[i for i in range(1, 19)], 
        needle_dis=['0800', '1000'],
        is_training=True
    )
    
    val_ds = EnhancedPeakDataset(
        file_dir, seq_len,
        range_list=[i for i in range(18, 21)],
        needle_dis=['0800', '1000'], 
        is_training=False
    )
    
    print(f"ğŸ“Š Train samples: {len(train_ds)}, Val samples: {len(val_ds)}")
    
    if len(train_ds) == 0 or len(val_ds) == 0:
        print("âŒ No data loaded! Check file paths and data.")
        return None, None
    
    # ìŠ¤ë§ˆíŠ¸ ìƒ˜í”ŒëŸ¬ ì‚¬ìš©
    try:
        smart_sampler = SmartBatchSampler(train_ds, batch_size, peak_ratio=0.4)
        train_loader = DataLoader(train_ds, batch_sampler=smart_sampler)
    except:
        print("âš ï¸ Smart sampler failed, using regular sampler")
        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)
    
    # ëª¨ë¸ ìƒì„±
    print("ğŸ—ï¸ Creating model...")
    model = MultiHeadPeakDetector(input_size=1, hidden_size=512, num_layers=2)
    
    # GPU 3ê°œ ì‚¬ìš© ì„¤ì •
    if torch.cuda.device_count() > 1:
        print(f"ğŸš€ Using {torch.cuda.device_count()} GPUs with DataParallel!")
        model = nn.DataParallel(model, device_ids=[0, 1, 2])
    model = model.to(device)
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í•™ìŠµ
    trainer = ComprehensiveTrainer(model, device)
    
    print("ğŸ“ Starting training...")
    final_results = trainer.train_progressive(train_loader, val_loader)
    
    return model, final_results

if __name__ == "__main__":
    try:
        model, results = main_training_pipeline()
        if results:
            print("\nâœ… Training completed successfully!")
            print("ğŸ“Š Final Results Summary:")
            for key, value in results.items():
                print(f"   {key}: {value:.4f}")
        else:
            print("âŒ Training failed!")
    except Exception as e:
        print(f"âŒ Error during training: {e}")
        import traceback
        traceback.print_exc()
